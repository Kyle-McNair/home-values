{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2010 = pd.read_csv(\"pop_2010.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2010 = pd.DataFrame(pop2010)\n",
    "\n",
    "pop2011 = pd.read_csv(\"pop_2011.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2011 = pd.DataFrame(pop2011)\n",
    "\n",
    "pop2012 = pd.read_csv(\"pop_2012.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2012 = pd.DataFrame(pop2012)\n",
    "\n",
    "pop2013 = pd.read_csv(\"pop_2013.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2013 = pd.DataFrame(pop2013)\n",
    "\n",
    "pop2014 = pd.read_csv(\"pop_2014.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2014 = pd.DataFrame(pop2014)\n",
    "\n",
    "pop2015 = pd.read_csv(\"pop_2015.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2015 = pd.DataFrame(pop2015)\n",
    "\n",
    "pop2016 = pd.read_csv(\"pop_2016.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2016 = pd.DataFrame(pop2016)\n",
    "\n",
    "pop2017 = pd.read_csv(\"pop_2017.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2017 = pd.DataFrame(pop2017)\n",
    "\n",
    "pop2018 = pd.read_csv(\"pop_2018.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2018 = pd.DataFrame(pop2018)\n",
    "\n",
    "pop2019 = pd.read_csv(\"pop_2019.csv\",encoding = \"ISO-8859-1\")\n",
    "pop2019 = pd.DataFrame(pop2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = [pop2010,pop2011,pop2012,pop2013,pop2014,pop2015,pop2016,pop2017,pop2018,pop2019]\n",
    "pop_merged = reduce(lambda left, right: pd.merge(left,right, on=['CBSAA'],how='inner'),pop)\n",
    "\n",
    "name = []\n",
    "\n",
    "for index, row in pop_merged.iterrows():\n",
    "    name.append(row['NAME_y'][0])\n",
    "\n",
    "pop_merged = pop_merged.drop(pop_merged.columns[[5,7,8,10,11,13,14,16,17,19,20,22,23,25,26,28,29]], axis=1)\n",
    "pop_merged['Name'] = name\n",
    "\n",
    "pop_merged['Name'] = pop_merged['Name'].str.replace('Micro Area','')\n",
    "pop_merged['Name'] = pop_merged['Name'].str.replace('Metro Area','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBSAA</th>\n",
       "      <th>2010_Pop</th>\n",
       "      <th>2011_Pop</th>\n",
       "      <th>2012_Pop</th>\n",
       "      <th>2013_Pop</th>\n",
       "      <th>2014_Pop</th>\n",
       "      <th>2015_Pop</th>\n",
       "      <th>2016_Pop</th>\n",
       "      <th>2017_Pop</th>\n",
       "      <th>2018_Pop</th>\n",
       "      <th>2019_Pop</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10140</td>\n",
       "      <td>72797</td>\n",
       "      <td>72546</td>\n",
       "      <td>71692</td>\n",
       "      <td>71078</td>\n",
       "      <td>70818</td>\n",
       "      <td>71122</td>\n",
       "      <td>71628</td>\n",
       "      <td>72697</td>\n",
       "      <td>73901</td>\n",
       "      <td>75061</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10180</td>\n",
       "      <td>165252</td>\n",
       "      <td>165858</td>\n",
       "      <td>167800</td>\n",
       "      <td>168144</td>\n",
       "      <td>166900</td>\n",
       "      <td>168922</td>\n",
       "      <td>170860</td>\n",
       "      <td>169747</td>\n",
       "      <td>174006</td>\n",
       "      <td>171795</td>\n",
       "      <td>Abilene, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10300</td>\n",
       "      <td>99892</td>\n",
       "      <td>99440</td>\n",
       "      <td>98987</td>\n",
       "      <td>99188</td>\n",
       "      <td>99047</td>\n",
       "      <td>98573</td>\n",
       "      <td>98504</td>\n",
       "      <td>98623</td>\n",
       "      <td>98266</td>\n",
       "      <td>98451</td>\n",
       "      <td>Adrian, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10380</td>\n",
       "      <td>306292</td>\n",
       "      <td>304633</td>\n",
       "      <td>304727</td>\n",
       "      <td>327847</td>\n",
       "      <td>322079</td>\n",
       "      <td>313209</td>\n",
       "      <td>309764</td>\n",
       "      <td>306000</td>\n",
       "      <td>292919</td>\n",
       "      <td>288877</td>\n",
       "      <td>Aguadilla-Isabela-San Sebastián, PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10420</td>\n",
       "      <td>703200</td>\n",
       "      <td>701456</td>\n",
       "      <td>702262</td>\n",
       "      <td>705686</td>\n",
       "      <td>703825</td>\n",
       "      <td>704243</td>\n",
       "      <td>702221</td>\n",
       "      <td>703505</td>\n",
       "      <td>704845</td>\n",
       "      <td>703479</td>\n",
       "      <td>Akron, OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CBSAA  2010_Pop  2011_Pop  2012_Pop  2013_Pop  2014_Pop  2015_Pop  \\\n",
       "0  10140     72797     72546     71692     71078     70818     71122   \n",
       "1  10180    165252    165858    167800    168144    166900    168922   \n",
       "2  10300     99892     99440     98987     99188     99047     98573   \n",
       "3  10380    306292    304633    304727    327847    322079    313209   \n",
       "4  10420    703200    701456    702262    705686    703825    704243   \n",
       "\n",
       "   2016_Pop  2017_Pop  2018_Pop  2019_Pop  \\\n",
       "0     71628     72697     73901     75061   \n",
       "1    170860    169747    174006    171795   \n",
       "2     98504     98623     98266     98451   \n",
       "3    309764    306000    292919    288877   \n",
       "4    702221    703505    704845    703479   \n",
       "\n",
       "                                   Name  \n",
       "0                         Aberdeen, WA   \n",
       "1                          Abilene, TX   \n",
       "2                           Adrian, MI   \n",
       "3  Aguadilla-Isabela-San Sebastián, PR   \n",
       "4                            Akron, OH   "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc2010 = pd.read_csv(\"income_2010.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2010 = pd.DataFrame(inc2010)\n",
    "\n",
    "inc2011 = pd.read_csv(\"income_2011.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2011 = pd.DataFrame(inc2011)\n",
    "\n",
    "inc2012 = pd.read_csv(\"income_2012.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2012 = pd.DataFrame(inc2012)\n",
    "\n",
    "inc2013 = pd.read_csv(\"income_2013.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2013 = pd.DataFrame(inc2013)\n",
    "\n",
    "inc2014 = pd.read_csv(\"income_2014.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2014 = pd.DataFrame(inc2014)\n",
    "\n",
    "inc2015 = pd.read_csv(\"income_2015.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2015 = pd.DataFrame(inc2015)\n",
    "\n",
    "inc2016 = pd.read_csv(\"income_2016.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2016 = pd.DataFrame(inc2016)\n",
    "\n",
    "inc2017 = pd.read_csv(\"income_2017.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2017 = pd.DataFrame(inc2017)\n",
    "\n",
    "inc2018 = pd.read_csv(\"income_2018.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2018 = pd.DataFrame(inc2018)\n",
    "\n",
    "inc2019 = pd.read_csv(\"income_2019.csv\",encoding = \"ISO-8859-1\")\n",
    "inc2019 = pd.DataFrame(inc2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = [inc2010,inc2011,inc2012,inc2013,inc2014,inc2015,inc2016,inc2017,inc2018,inc2019]\n",
    "income_merged = reduce(lambda left, right: pd.merge(left,right, on=['CBSAA'],how='inner'),income)\n",
    "\n",
    "name = []\n",
    "\n",
    "for index, row in income_merged.iterrows():\n",
    "    name.append(row['NAME_y'][0])\n",
    "\n",
    "income_merged = income_merged.drop(income_merged.columns[[5,7,8,10,11,13,14,16,17,19,20,22,23,25,26,28,29]], axis=1)\n",
    "income_merged['Name'] = name\n",
    "\n",
    "income_merged['Name'] = income_merged['Name'].str.replace('Micro Area','')\n",
    "income_merged['Name'] = income_merged['Name'].str.replace('Metro Area','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBSAA</th>\n",
       "      <th>2010_Income</th>\n",
       "      <th>2011_Income</th>\n",
       "      <th>2012_Income</th>\n",
       "      <th>2013_Income</th>\n",
       "      <th>2014_Income</th>\n",
       "      <th>2015_Income</th>\n",
       "      <th>2016_Income</th>\n",
       "      <th>2017_Income</th>\n",
       "      <th>2018_Income</th>\n",
       "      <th>2019_Income</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10140</td>\n",
       "      <td>40019</td>\n",
       "      <td>40993</td>\n",
       "      <td>42057</td>\n",
       "      <td>41315</td>\n",
       "      <td>43356</td>\n",
       "      <td>44122</td>\n",
       "      <td>49623</td>\n",
       "      <td>47445</td>\n",
       "      <td>48255</td>\n",
       "      <td>61026</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10180</td>\n",
       "      <td>40630</td>\n",
       "      <td>40659</td>\n",
       "      <td>43407</td>\n",
       "      <td>44149</td>\n",
       "      <td>44303</td>\n",
       "      <td>47420</td>\n",
       "      <td>48016</td>\n",
       "      <td>51130</td>\n",
       "      <td>48021</td>\n",
       "      <td>54808</td>\n",
       "      <td>Abilene, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10300</td>\n",
       "      <td>45563</td>\n",
       "      <td>44509</td>\n",
       "      <td>48224</td>\n",
       "      <td>45938</td>\n",
       "      <td>46739</td>\n",
       "      <td>48279</td>\n",
       "      <td>51918</td>\n",
       "      <td>56515</td>\n",
       "      <td>55378</td>\n",
       "      <td>53865</td>\n",
       "      <td>Adrian, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10380</td>\n",
       "      <td>14313</td>\n",
       "      <td>14951</td>\n",
       "      <td>15339</td>\n",
       "      <td>15323</td>\n",
       "      <td>15886</td>\n",
       "      <td>14485</td>\n",
       "      <td>14546</td>\n",
       "      <td>16645</td>\n",
       "      <td>17064</td>\n",
       "      <td>16311</td>\n",
       "      <td>Aguadilla-Isabela-San Sebastián, PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10420</td>\n",
       "      <td>46521</td>\n",
       "      <td>47032</td>\n",
       "      <td>49731</td>\n",
       "      <td>49984</td>\n",
       "      <td>50538</td>\n",
       "      <td>51580</td>\n",
       "      <td>51598</td>\n",
       "      <td>56106</td>\n",
       "      <td>60019</td>\n",
       "      <td>57158</td>\n",
       "      <td>Akron, OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CBSAA  2010_Income  2011_Income  2012_Income  2013_Income  2014_Income  \\\n",
       "0  10140        40019        40993        42057        41315        43356   \n",
       "1  10180        40630        40659        43407        44149        44303   \n",
       "2  10300        45563        44509        48224        45938        46739   \n",
       "3  10380        14313        14951        15339        15323        15886   \n",
       "4  10420        46521        47032        49731        49984        50538   \n",
       "\n",
       "   2015_Income  2016_Income  2017_Income  2018_Income  2019_Income  \\\n",
       "0        44122        49623        47445        48255        61026   \n",
       "1        47420        48016        51130        48021        54808   \n",
       "2        48279        51918        56515        55378        53865   \n",
       "3        14485        14546        16645        17064        16311   \n",
       "4        51580        51598        56106        60019        57158   \n",
       "\n",
       "                                   Name  \n",
       "0                         Aberdeen, WA   \n",
       "1                          Abilene, TX   \n",
       "2                           Adrian, MI   \n",
       "3  Aguadilla-Isabela-San Sebastián, PR   \n",
       "4                            Akron, OH   "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = pd.merge(pop_merged,income_merged, on=['CBSAA'],how='inner')\n",
    "combine.to_csv('MSA_Pop_and_Income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2010 = pd.read_csv(\"hv_2010.csv\",encoding = \"ISO-8859-1\")\n",
    "h2010 = pd.DataFrame(h2010)\n",
    "\n",
    "h2011 = pd.read_csv(\"hv_2011.csv\",encoding = \"ISO-8859-1\")\n",
    "h2011 = pd.DataFrame(h2011)\n",
    "\n",
    "h2012 = pd.read_csv(\"hv_2012.csv\",encoding = \"ISO-8859-1\")\n",
    "h2012 = pd.DataFrame(h2012)\n",
    "\n",
    "h2013 = pd.read_csv(\"hv_2013.csv\",encoding = \"ISO-8859-1\")\n",
    "h2013 = pd.DataFrame(h2013)\n",
    "\n",
    "h2014 = pd.read_csv(\"hv_2014.csv\",encoding = \"ISO-8859-1\")\n",
    "h2014 = pd.DataFrame(h2014)\n",
    "\n",
    "h2015 = pd.read_csv(\"hv_2015.csv\",encoding = \"ISO-8859-1\")\n",
    "h2015 = pd.DataFrame(h2015)\n",
    "\n",
    "h2016 = pd.read_csv(\"hv_2016.csv\",encoding = \"ISO-8859-1\")\n",
    "h2016 = pd.DataFrame(h2016)\n",
    "\n",
    "h2017 = pd.read_csv(\"hv_2017.csv\",encoding = \"ISO-8859-1\")\n",
    "h2017 = pd.DataFrame(h2017)\n",
    "\n",
    "h2018 = pd.read_csv(\"hv_2018.csv\",encoding = \"ISO-8859-1\")\n",
    "h2018 = pd.DataFrame(h2018)\n",
    "\n",
    "h2019 = pd.read_csv(\"hv_2019.csv\",encoding = \"ISO-8859-1\")\n",
    "h2019 = pd.DataFrame(h2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = [h2010,h2011,h2012,h2013,h2014,h2015,h2016,h2017,h2018,h2019]\n",
    "homes_merged = reduce(lambda left, right: pd.merge(left,right, on=['CBSAA'],how='inner'),homes)\n",
    "\n",
    "name = []\n",
    "\n",
    "for index, row in homes_merged.iterrows():\n",
    "    name.append(row['NAME_y'][0])\n",
    "\n",
    "homes_merged = homes_merged.drop(homes_merged.columns[[5,7,8,10,11,13,14,16,17,19,20,22,23,25,26,28,29]], axis=1)\n",
    "homes_merged['Name'] = name\n",
    "\n",
    "homes_merged['Name'] = homes_merged['Name'].str.replace('Micro Area','')\n",
    "homes_merged['Name'] = homes_merged['Name'].str.replace('Metro Area','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine2 = pd.merge(combine,homes_merged, on=['CBSAA'],how='inner')\n",
    "combine2.to_csv('MSA_Pop_Income_Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(pop2010,inc2010, on=['CBSAA'],how='inner')\n",
    "df1a = pd.merge(df1, h2010, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df1a = df1a.rename(columns={\"2010_Pop\": \"Population\", \"2010_Income\":\"Income\",\"2010_home_value\":\"Home_Value\"})\n",
    "df1a = df1a.drop(df1a.columns[[0,2,4,5]], axis = 1)\n",
    "df1a = df1a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df2 = pd.merge(pop2011,inc2011, on=['CBSAA'],how='inner')\n",
    "df2a = pd.merge(df2, h2011, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df2a = df2a.rename(columns={\"2011_Pop\": \"Population\", \"2011_Income\":\"Income\",\"2011_home_value\":\"Home_Value\"})\n",
    "df2a = df2a.drop(df2a.columns[[0,2,4,5]], axis = 1)\n",
    "df2a = df2a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df3 = pd.merge(pop2012,inc2012, on=['CBSAA'],how='inner')\n",
    "df3a = pd.merge(df3, h2012, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df3a = df3a.rename(columns={\"2012_Pop\": \"Population\", \"2012_Income\":\"Income\",\"2012_home_value\":\"Home_Value\"})\n",
    "df3a = df3a.drop(df3a.columns[[0,2,4,5]], axis = 1)\n",
    "df3a = df3a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df4 = pd.merge(pop2013,inc2013, on=['CBSAA'],how='inner')\n",
    "df4a = pd.merge(df4, h2013, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df4a = df4a.rename(columns={\"2013_Pop\": \"Population\", \"2013_Income\":\"Income\",\"2013_home_value\":\"Home_Value\"})\n",
    "df4a = df4a.drop(df4a.columns[[0,2,4,5]], axis = 1)\n",
    "df4a = df4a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df5 = pd.merge(pop2014,inc2014, on=['CBSAA'],how='inner')\n",
    "df5a = pd.merge(df5, h2014, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df5a = df5a.rename(columns={\"2014_Pop\": \"Population\", \"2014_Income\":\"Income\",\"2014_home_value\":\"Home_Value\"})\n",
    "df5a = df5a.drop(df5a.columns[[0,2,4,5]], axis = 1)\n",
    "df5a = df5a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df6 = pd.merge(pop2015,inc2015, on=['CBSAA'],how='inner')\n",
    "df6a = pd.merge(df6, h2015, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df6a = df6a.rename(columns={\"2015_Pop\": \"Population\", \"2015_Income\":\"Income\",\"2015_home_value\":\"Home_Value\"})\n",
    "df6a = df6a.drop(df6a.columns[[0,2,4,5]], axis = 1)\n",
    "df6a = df6a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df7 = pd.merge(pop2016,inc2016, on=['CBSAA'],how='inner')\n",
    "df7a = pd.merge(df7, h2016, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df7a = df7a.rename(columns={\"2016_Pop\": \"Population\", \"2016_Income\":\"Income\",\"2016_home_value\":\"Home_Value\"})\n",
    "df7a = df7a.drop(df7a.columns[[0,2,4,5]], axis = 1)\n",
    "df7a = df7a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df8 = pd.merge(pop2017,inc2017, on=['CBSAA'],how='inner')\n",
    "df8a = pd.merge(df8, h2017, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df8a = df8a.rename(columns={\"2017_Pop\": \"Population\", \"2017_Income\":\"Income\",\"2017_home_value\":\"Home_Value\"})\n",
    "df8a = df8a.drop(df8a.columns[[0,2,4,5]], axis = 1)\n",
    "df8a = df8a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df9 = pd.merge(pop2018,inc2018, on=['CBSAA'],how='inner')\n",
    "df9a = pd.merge(df9, h2018, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df9a = df9a.rename(columns={\"2018_Pop\": \"Population\", \"2018_Income\":\"Income\",\"2018_home_value\":\"Home_Value\"})\n",
    "df9a = df9a.drop(df9a.columns[[0,2,4,5]], axis = 1)\n",
    "df9a = df9a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]\n",
    "########################################################################################\n",
    "df10 = pd.merge(pop2019,inc2019, on=['CBSAA'],how='inner')\n",
    "df10a = pd.merge(df10, h2019, on = ['CBSAA'],how = \"inner\")\n",
    "\n",
    "df10a = df10a.rename(columns={\"2019_Pop\": \"Population\", \"2019_Income\":\"Income\",\"2019_home_value\":\"Home_Value\"})\n",
    "df10a = df10a.drop(df10a.columns[[0,2,4,5]], axis = 1)\n",
    "df10a = df10a[['YEAR','NAME','CBSAA','Population','Income','Home_Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frames = [df1a,df2a,df3a,df4a,df5a,df6a,df7a,df8a,df9a,df10a]\n",
    "new_merge = pd.concat(df_frames)\n",
    "new_merge['NAME'] = new_merge['NAME'].str.replace('Micro Area','')\n",
    "new_merge['NAME'] = new_merge['NAME'].str.replace('Metro Area','')\n",
    "new_merge.to_csv('MSA_Pop_Income_Housing2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
